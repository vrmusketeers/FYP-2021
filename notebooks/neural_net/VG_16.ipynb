{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VG-16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrmusketeers/FYP-2021/blob/master/notebooks/neural_net/VG_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQD3qtKM-9Jq",
        "outputId": "6d34ac37-c4ac-489c-f47a-47e7256dcfa9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnY9El_MNq3z"
      },
      "source": [
        "!rm -rf '/content/drive/Shareddrives/Final Project/FmriTrainTestData/VG16-Data/Output/train/.ipynb_checkpoints'\n",
        "!rm -rf '/content/drive/Shareddrives/Final Project/FmriTrainTestData/VG16-Data/Output/test/.ipynb_checkpoints'\n",
        "!rm -rf '/content/drive/Shareddrives/Final Project/FmriTrainTestData/VG16-Data/Output/val/.ipynb_checkpoints'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nG0ZYeEhZFt"
      },
      "source": [
        "import os \n",
        "import zipfile \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
        "from tensorflow.keras import layers \n",
        "from tensorflow.keras import Model \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAtIB-aYev7a"
      },
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNSkWq8jhces",
        "outputId": "9563ae3e-6a35-4d72-cbae-fd52bd404349"
      },
      "source": [
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory('/content/drive/Shareddrives/Final Project/FmriTrainTestData/VG16-Data/Output/train', batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory('/content/drive/Shareddrives/Final Project/FmriTrainTestData/VG16-Data/Output/val',  batch_size = 20, class_mode = 'binary', target_size = (224, 224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6968 images belonging to 2 classes.\n",
            "Found 871 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0esYuJvh2Kn",
        "outputId": "e54fcdfb-5095-450c-da94-611a20927435"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIPd_zLGjk7-"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y78-Mo8Qjlv9",
        "outputId": "2a8f9319-51b9-4c12-c2fc-c83cf31378f5"
      },
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(base_model.output)\n",
        "\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "# Add a dropout rate of 0.5\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Add a final sigmoid layer with 1 node for classification output\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.models.Model(base_model.input, x)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), loss = 'binary_crossentropy',metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SshjKpWNlE6w",
        "outputId": "4a42cd22-f687-4613-9a83-39db1f0c57d6"
      },
      "source": [
        "vgghist = model.fit(train_generator, validation_data = validation_generator, steps_per_epoch = 30, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 692s 23s/step - loss: 1.0735 - acc: 0.4800 - val_loss: 0.7217 - val_acc: 0.5350\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 257s 9s/step - loss: 0.7737 - acc: 0.4900 - val_loss: 0.6941 - val_acc: 0.5029\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 234s 8s/step - loss: 0.7375 - acc: 0.5300 - val_loss: 0.6983 - val_acc: 0.5373\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 211s 7s/step - loss: 0.7120 - acc: 0.5117 - val_loss: 0.6885 - val_acc: 0.5396\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 196s 6s/step - loss: 0.6951 - acc: 0.5650 - val_loss: 0.6996 - val_acc: 0.4834\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 167s 6s/step - loss: 0.7055 - acc: 0.5383 - val_loss: 0.7023 - val_acc: 0.5373\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 166s 5s/step - loss: 0.6974 - acc: 0.5317 - val_loss: 0.6969 - val_acc: 0.5373\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 138s 5s/step - loss: 0.7068 - acc: 0.4883 - val_loss: 0.6905 - val_acc: 0.5258\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 124s 4s/step - loss: 0.6966 - acc: 0.5533 - val_loss: 0.6964 - val_acc: 0.5373\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 129s 4s/step - loss: 0.6977 - acc: 0.5333 - val_loss: 0.6909 - val_acc: 0.5155\n"
          ]
        }
      ]
    }
  ]
}